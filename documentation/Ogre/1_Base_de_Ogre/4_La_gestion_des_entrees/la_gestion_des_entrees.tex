

\chapter{La gestion des entrées}




\section{Les frame listeners}





\subsection{Des ''écouteurs d'images'' ?}
\subsubsection{Utilité}
Lorsque vous gérez les entrées de l'utilisateur (et même pour faire des calculs divers durant l'exécution de votre programme), l'ordinateur effectue les instructions nécessaires entre deux images (ou frames en anglais), donc pendant un temps très court.

En pratique, le moteur fonctionne dans une boucle, qui ne fait qu'afficher une image, puis fait des calculs; et ainsi de suite, sans s'arrêter. Il est donc possible pour le programmeur de donner ses instructions avant qu'une image soit rendue, ou bien après, ou bien même pendant que la carte graphique fait le rendu graphique.

Lorsque l'on aura vu comment créer cette boucle de rendu, nous serons à même de donner les instructions de la manière dont nous le désirons. En attendant, je vais vous présenter une classe qui a l'avantage de permettre de faire tout ce que je viens de vous expliquer de façon très simple: le frame listener.



\subsubsection{Les méthodes à connaître}
Un frame listener est une classe interface qui possède trois méthodes, dont voici les prototypes:

\begin{itemize}
\item virtual bool frameStarted(const FrameEvent\& evt): est appelée avant que la frame ne soit rendue (frameStarted)
\item virtual bool frameRenderingQueued(const FrameEvent\& evt): est appelée après que la frame ait été rendue (frameEnded)
\item virtual bool frameEnded(const FrameEvent\& evt): est appelée après que le processeur graphique ait reçu les instructions pour le rendu (frameRenderingQueued)\newline
\end{itemize}
    


En créant un objet dérivé de la classe frame listener dans votre application et en réimplémentant ces méthodes virtuelles, vous avez donc la possibilité de demander à Ogre d'effectuer les calculs dont vous avez besoin à chaque image.



frameStarted() et frameEnded() sont très similaires, étant donné qu'elles ont pour seule différence d'être appelées respectivement au début et à la fin de la boucle de rendu. Mais comme on est dans une boucle, en réalité il ne se passe quasiment rien entre l'appel à frameEnded() et celui à frameStarted(). La différence peut être utile par exemple si vous avez un calcul qui semble plus logique d'effectuer après que l'image soit rendue plutôt qu'avant, mais ce n'est qu'une question de lecture du code selon moi.


En revanche la dernière (frameRenderingQueued) est plus subtile. Comme je l'ai dit, elle est appelée dès que la carte graphique reçoit les instructions nécessaires pour afficher l'image à rendre.


Vous le savez probablement, c'est une opération très co\^uteuse en ressources et c'est souvent ce qui ralentit les jeux vidéo mettant en jeu de nombreux effets graphiques. Pendant ce temps-là, le processeur central attend que ça se passe. Par conséquent, si vous appelez la méthode frameRenderingQueued() pour faire des calculs, vous évitez d'avoir un processeur peu occupé pendant que la carte graphique fait son boulot !

De manière générale, on pourra utiliser cette méthode pour des opérations lourdes dont on sait qu'elles seront répétées à chaque image, afin de rentabiliser l'utilisation du processeur.




\subsubsection{Contrôle de l'exécution}

La valeur de retour des méthodes d'un frame listener est un booléen récupéré par Ogre pour savoir s'il doit continuer (true) ou non (false) l'exécution du programme.



\subsubsection{Utiliser plusieurs frame listeners}

Il est possible de créer autant de frame listeners que vous le désirez, pour effectuer des opérations diverses. En revanche, il est conseillé de ne pas en abuser pour éviter de trop segmenter votre application, il peut être intéressant d'appeler d'autres fonctions à partir d'un frame listener plutôt que d'en créer trop.

Enfin, et c'est là le plus important:
\textbf{L'ordre d'exécution des frame listeners est laissé aux soins du moteur. Vous n'avez AUCUN contrôle dessus !}

En d'autres termes, si vous avez besoin d'effectuer des opérations dans un ordre précis, ne les mettez pas dans des frame listeners différents, car vous ne pourrez pas décider de l'ordre d'exécution. Il faut alors laisser un seul frame listener gérer les opérations, ou ne pas passer par eux (ce sera possible lorsque nous attaquerons la boucle de rendu).



\subsection{Le frame listener en pratique}

Comme nous allons vouloir redéfinir les méthodes du frame listener, il faut en faire une classe dérivée. Vu que nous sommes dans la gestion des entrées, nous allons tout de suite préparer le terrain en créant une classe InputListener dérivant de ExampleFrameListener.

Je dérive ici de la classe ExampleFrameListener, elle-même dérivée de FrameListener, car la classe ExampleApplication met déjà en place une gestion des entrées et attend un ExampleFrameListener. Cette classe s'occupe aussi de construire les objets nécessaires à l'écoute des entrées souris/clavier, ce que nous aborderons ultérieurement.
Cependant, la méthode de traitement reste identique, nous allons juste devoir redéfinir frameRenderingQueued() pour implémenter notre propre gestion des entrées à la place de celle prévue par ExampleFrameListener.


\begin{lstlisting}[caption={InputListener.h}]
#include ''ExampleFrameListener.h''
class InputListener: public ExampleFrameListener
{
public:
    InputListener(RenderWindow* win, Camera* cam, sceneManager *sceneMgr, bool bufferedKeys = false, bool bufferedMouse = false, bool bufferedJoy = false );
    virtual bool frameRenderingQueued(const FrameEvent& evt);

private:
    Ogre::sceneManager *msceneMgr; //pointeur sur le scene Manager, qui servira a retrouver des objets dans la scene.
    bool mToucheAppuyee;	 //pour garder une trace de l etat dans lequel se trouve une touche particuliere.

    /*distance de deplacement de la camera et sa vitesse, puis des angles de rotation.*/
    Ogre::Real mMouvement;
    Ogre::Real mVitesse;
    Ogre::Real mVitesseRotation;

	/*angles de rotation.*/
    Ogre::Radian mRotationX;
    Ogre::Radian mRotationY;
};
\end{lstlisting}



Dans votre fichier InputListener.cpp, préparez le constructeur ainsi que l'implémentation des méthodes, avec un corps vide pour l'instant:

%je ne sais pas si [language=cpp] passe et s il est utile
\begin{lstlisting}[caption={InputListener.cpp}]
/*
Arguments:
RenderWindow* win: votre RenderWindow pour l'application
Camera* cam: la camera que vous utilisez
sceneManager *sceneMgr: le scene Manager
bool bufferedKeys: indique si vous desirez utiliser le buffer pour le clavier
bool bufferedMouse: indique si vous desirez utiliser le buffer pour la souris
bool bufferedJoy: indique si vous desirez utiliser le buffer pour le joystick
*/
InputListener::InputListener(RenderWindow* win, Camera* cam, sceneManager *sceneMgr, bool bufferedKeys, bool bufferedMouse, bool bufferedJoy) 
      : ExampleFrameListener(win, cam, bufferedKeys, bufferedMouse, bufferedJoy)
{
    msceneMgr = sceneMgr;
    mVitesse = 100;
    mVitesseRotation = 0.3;
    mToucheAppuyee = false;
}
\end{lstlisting}



Il n'y a pas de constructeur écrit pour les frame listeners, car c'est une classe interface\footnote{que je sache il n'y a pas d'interface en C++}\footnote{pas de constructeur parce que c'est une classe interface ??}, seules les trois méthodes que j'ai présentées plus haut importent. En revanche, la classe ExampleFrameListener possède un constructeur qui prépare le terrain pour l'utilisation des entrées, que j'appelle dans ma classe dérivée. 

Les trois booléens en paramètres indiquent si vous désirez utiliser le buffer respectivement pour le clavier, la souris et le joystick. Comme ce sera l'objet de la dernière partie de ce chapitre, je mets par défaut false (dans le .h).

Dans le corps du constructeur, j'initialise mes attributs mSceneMgr, mVitesse et mToucheAppuyee, qui nous serviront par la suite.

Il n'y a pas d'attribut à ajouter dans notre classe PremiereApplication, la classe ExampleApplication contient déjà un pointeur sur un ExampleFrameListener.

       




































\section{OIS}


Pour gérer les entrées de l'utilisateur, nous allons utiliser la bibliothèque OIS \footnote{Object Oriented Input System, c'est à dire: Système d'entrées orienté objet}, qui est distribuée par défaut avec le SDK d'Ogre. Comme je l'ai dit en introduction de ce cours, un moteur 3D n'a pas de méthodes pour gérer autre chose que ce qui s'affiche sur votre écran. C'est pourquoi nous utiliserons cette bibliothèque pour récupérer les actions du joueur.\newline


Pour ce faire, OIS représente les périphériques d'entrée par des objets, qui sont les suivants:

\begin{itemize}
\item Mouse pour la souris;
\item Keyboard pour le clavier;
\item Joystick pour les joysticks ou manettes de jeu.\newline
\end{itemize}
    



Qui dit nouvelle bibliothèque dit nouveau namespace ! Ces classes se trouvent donc dans l'espace de nom OIS.\newline

Les touches du clavier et les boutons de la souris sont des énumérations, définies comme ceci:

\begin{itemize}
\item OIS::KC\_NOMDELATOUCHE pour le clavier;
\item OIS::MB\_NOMDUBOUTON pour la souris.
\end{itemize}


Ce qui donne par exemple OIS::KC\_A pour la touche 'A'\footnote{la touche 'Entrée' s'appelle 'Return' en anglais, ne cherchez donc pas OIS::KC\_ENTER, vous ne trouverez pas.}, ou OIS::MC\_Left pour le clic gauche.\newline

Une dernière chose bonne à savoir: les codes de touches d'OIS correspondent aux touches physiques d'un clavier QWERTY. Ce qui signifie par exemple que OIS::KC\_A correspond à la touche Q sur votre clavier AZERTY.\newline

Afin d'utiliser OIS, il faut inclure le header correspondant. Celui-ci se trouve dans le dossier OIS du dossier include, on ajoutera donc la ligne de préprocesseur suivante en tête du header de InputListener:

\begin{lstlisting}[caption={Include OIS}]
#include <OIS/OIS.h>
\end{lstlisting}

Bien s\^ur, vous pouvez aussi ajouter le répertoire OIS à la liste des includes de votre IDE pour éviter d'avoir à le préciser dans le code.




























\section{Allons-y sans buffer}\footnote{Le tutorial du site de Ogre ''Frame Listeners and Unbuffered Input'' présente le point traité ici d'une autre manière \href{http://www.ogre3d.org/tikiwiki/Basic+Tutorial+4}{Frame Listeners and Unbuffered Input}}
\subsection{Explications}
Dans le constructeur de notre frame listener, je vous ai dit que l'on avait mis les paramètres concernant l'utilisation du buffer à false, car c'est l'objet de la dernière partie de ce chapitre. Mais que signifie le fait d'utiliser ou non le buffer ?

Lorsque vous appuyez sur une touche, le clavier envoie un signal à l'ordinateur pour lui dire qu'une touche est actuellement pressée, en précisant quelle touche est concernée. Ce signal est envoyé tant que la touche reste enfoncée.

De son coté, notre programme effectue sa boucle infinie, rendant les images et faisant les calculs demandés. Supposons que vous appuyez sur une touche à un instant donné. Lorsque l'ordinateur arrivera à l'instruction lui demandant de regarder ce qui se passe sur le clavier, il va voir qu'une touche est enfoncée et cherchera à effectuer les opérations demandées, et ceci tant que la touche reste enfoncée. Mais il n'est pas possible pour l'ordinateur de faire seul la différence entre une touche enfoncée et une touche qui vient d'être enfoncée.

Nous allons donc voir comment régler ce problème ''à la main'', puis nous verrons l'utilisation du buffer, qui constitue une autre façon de traiter l'entrée.

\subsection{Création du frame listener}

Avant de passer à la suite, réimplémentez la méthode createFrameListener() présente dans ExampleApplication dans la classe PremiereApplication en ajoutant le prototype et la définition :

\begin{lstlisting}[caption={PremiereApplication::createFrameListener}]
void PremiereApplication::createFrameListener()
{
    //creation du framelistener en utilisant le ctor prepare plus tot
    mFrameListener= new InputListener(mWindow, mCamera, mSceneMgr, false, false, false);
    //signale a l objet root que ns avons un nv frame listener et qu il faudra l'appeler
    mRoot->addFrameListener(mFrameListener);
}
\end{lstlisting}

Le root est l'élément de base de l'application Ogre qui s'occupe notamment de gérer les frame listeners, nous le reverrons plus tard en approfondissant le fonctionnement du moteur.
 









\subsection{Déplacer la caméra}


Tout d'abord, nous allons considérer le déplacement de caméra, pour lequel nous n'avons pas besoin de savoir si la touche vient d'être appuyée : c'est simplement son état actuel qui compte.

Premièrement, il nous faut récupérer l'état actuel du clavier et de la souris. Localisez la méthode frameRenderingQueued() de votre InputListener et insérez-y ceci :


\begin{lstlisting}[caption={}]
if(mMouse)
    mMouse->capture();
if(mKeyboard)
    mKeyboard->capture();
\end{lstlisting}

Ces deux lignes permettent de mettre à jour nos objets pour obtenir le nom des touches enfoncées.\newline

Vérifions d'abord si la touche Echap est utilisée, auquel cas nous quitterons l'application.


\begin{lstlisting}[caption={}]
if(mKeyboard->isKeyDown(OIS::KC_ESCAPE))
    return false;
\end{lstlisting}

Nous devons ensuite mettre à jour la valeur de mMouvement, qui sera la distance parcourue par la caméra si une direction est choisie. Comme le nombre d'images par seconde est variable, nous utilisons la propriété timeSinceLastFrame de l'événement, multipliée par la vitesse de la caméra. Le produit de la vitesse par le temps écoulé nous donne donc la distance parcourue.

J'ai aussi créé un vecteur dans lequel nous allons enregistrer les déplacements à effectuer. En effet, on peut utiliser plusieurs touches en même temps, il faut donc additionner les directions demandées, et les conserver pour déplacer la caméra en une seule fois.


\begin{lstlisting}[caption={}]
Ogre::Vector3 deplacement = Ogre::Vector3::ZERO;
mMouvement = mVitesse * evt.timeSinceLastFrame;
\end{lstlisting}

Nous allons utiliser les flèches du clavier et les touches Z, S, Q, D pour nous déplacer ; j'ai aussi implémenté les touches fléchées, qui sont une configuration alternative pour le déplacement. Il faut donc vérifier si les touches qui nous intéressent sont enfoncées :


\begin{lstlisting}[caption={}]
// La touche A d'un clavier QWERTY correspond au Q sur un AZERTY
if(mKeyboard->isKeyDown(OIS::KC_LEFT) || mKeyboard->isKeyDown(OIS::KC_A)) 
    deplacement.x -= mMouvement;

if(mKeyboard->isKeyDown(OIS::KC_RIGHT) || mKeyboard->isKeyDown(OIS::KC_D))
    deplacement.x += mMouvement;
    
// W correspond au Z du AZERTY
if(mKeyboard->isKeyDown(OIS::KC_UP) || mKeyboard->isKeyDown(OIS::KC_W)) 
    deplacement.z -= mMouvement;

if(mKeyboard->isKeyDown(OIS::KC_DOWN) || mKeyboard->isKeyDown(OIS::KC_S))
    deplacement.z += mMouvement;
\end{lstlisting}

Attention aux signes ! Vous devez respecter ce que nous avons vu dans le chapitre sur les déplacements !\footnote{hein? de quoi parle t il?}

Le déplacement de la caméra fonctionne, il ne manque plus que la rotation de celle-ci. Il nous suffit pour cela de récupérer le déplacement relatif depuis la dernière fois que la souris a bougé (depuis le dernier appel à frameRenderingQueued() donc).

Pour retrouver cette valeur, on passe successivement par les attributs suivants :
\begin{itemize}
\item le mouseState contenu dans l'objet souris, contenant diverses informations sur l'état de la souris ;
\item l'axe que l'on désire observer : ici, ce sera X ou Y pour le yaw ou le pitch ;
\item le déplacement relatif de la souris suivant cet axe.
\end{itemize}

Maintenant, occupons-nous du mouvement de la souris. Pour récupérer le déplacement de celle-ci, nous devons récupérer son état, comme indiqué dans le code suivant.


\begin{lstlisting}[caption={}]
const OIS::MouseState &mouseState = mMouse->getMouseState();
\end{lstlisting}

à partir de cette référence on peut notamment récupérer le déplacement de la souris depuis la dernière image, en appelant l'axe X ou Y puis l'attribut rel.


\begin{lstlisting}[caption={}]
mRotationX = Degree(-mouseState.Y.rel * mVitesseRotation);
mRotationY = Degree(-mouseState.X.rel * mVitesseRotation);
\end{lstlisting}

Il faut particulièrement faire attention aux axes et aux signes. Je considère que mRotationX (respectivement mRotationY) correspond à la rotation autour de l'axe X (respectivement Y), c'est-à-dire lorsque je déplace ma souris en avant ou en arrière (respectivement à gauche ou à droite). Or, le déplacement vers l'avant ou l'arrière de la souris correspond à son axe Y, c'est pour ça que je demande l'axe Y de la souris pour trouver la rotation autour de X dans l'espace 3D.

On rajoute une multiplication par la vitesse de rotation voulue et on convertit le tout en degrés, sinon le mouvement est bien trop rapide.

Enfin, on appelle les méthodes de rotation et de déplacement de la caméra :

\begin{lstlisting}[caption={}]
mCamera->yaw(mRotationY);
mCamera->pitch(mRotationX);
mCamera->moveRelative(deplacement);
\end{lstlisting}

La dernière ligne, comme vous le remarquez, déplace la caméra par rapport à son repère local, ce qui évite de faire la transformation de la variable deplacement à la main. Il est aussi possible de demander un déplacement par rapport au repère absolu avec Camera::move().


















\subsection{Et avec un noeud de scène ?}

J'en profite pour vous montrer comment on aurait procédé pour déplacer un noeud de scène par exemple, qui utilise la méthode translate().

Les deux lignes suivantes sont équivalentes :


\begin{lstlisting}[caption={}]
node->translate(deplacement, TS_LOCAL);
node->translate(node->getOrientation() * deplacement, TS_PARENT);
\end{lstlisting}


La première ligne est très similaire à celle utilisée pour la caméra, il suffit de préciser que l'on se déplace par rapport au repère local du noeud de scène.

La seconde solution indique un déplacement relatif au noeud parent, mais utilise le quaternion retourné par la méthode getOrientation() multiplié par le vecteur de déplacement pour obtenir la direction souhaitée dans ce repère. En pratique, on utilisera seulement la première ligne, plus courte et plus propre dans le code.







\subsection{}
Mini-TP : créer un interrupteur

Pour gérer un événement qui ne doit arriver qu'une fois lorsque la touche est appuyée, il y a une précaution supplémentaire à prendre. Je vous ai dit plus haut que votre ordinateur ne retenait pas l'état dans lequel se trouvait votre clavier ou votre souris à l'image précédente. Cependant, rien ne nous empêche de le faire nous-mêmes !

à titre d'exemple, disons que l'on veut utiliser la touche T pour allumer et éteindre la lumière de notre scène. Il va donc falloir vérifier à chaque image si la touche T est enfoncée, et si en plus ce n'était pas déjà le cas à l'image précédente. Pour cela, on utilisera l'attribut mToucheAppuyee de notre classe InputListener.

Un indice: le SceneManager possède une méthode getLight() qui permet de récupérer un pointeur sur une lumière à partir du nom de celle-ci...

à vos claviers ! La réponse se trouve juste après.



\begin{lstlisting}[caption={Capture de l'état ponctuel d'une touche}]
bool etatTouche = mKeyboard->isKeyDown(OIS::KC_T);
if(etatTouche && !mToucheAppuyee)
{
    Ogre::Light *light = mSceneMgr->getLight("lumiere1");
    light->setVisible(!light->isVisible());
}
mToucheAppuyee = etatTouche;
\end{lstlisting}





Tout d'abord, je récupère l'état actuel de ma touche T dans une variable locale. Je vérifie si la touche est actuellement enfoncée et si elle ne l'était pas déjà à l'aide de l'attribut mToucheAppuyee. Si ma condition est vérifiée, je récupère ma lumière, et je change son état (visible ou non).

Enfin, j'enregistre l'état actuel de ma touche T dans mToucheAppuyee, en prévision de la prochaine image!







\subsection{Code}


\begin{lstlisting}[caption={InputListener.h}]
#include "ExampleFrameListener.h"

//nous utiliserons OIS pour gerer les entrees de l'utilisateur
#include <OIS/OIS.h>

//la classe ExampleFrameListener ExampleApplication met deja en oeuvre une gestion des entrees et attend un ExampleFrameListener
//ExampleFrameListener s'occupe aussi de construire les objets necessaires a l'ecoute des entrees
class InputListener : public ExampleFrameListener
{
    public:
        InputListener(RenderWindow* win, Camera* cam, SceneManager *sceneMgr, 
                        bool bufferedKeys = false, bool bufferedMouse = false, 
                        bool bufferedJoy = false);
        
        //nous allons juste devoir redefinir frameRenderingQueued() pour implementer notre propre gestion des entrees a la place de celle prevue par ExampleFrameListener.
        virtual bool frameRenderingQueued(const FrameEvent& evt);

        private:
            Ogre::SceneManager *mSceneMgr;
            Ogre::Camera *mCamera;
            
            bool mContinuer;
            bool mToucheAppuyee;

            Ogre::Real mMouvement;
            Ogre::Real mVitesse;
            Ogre::Real mVitesseRotation;

            Ogre::Radian mRotationX;
            Ogre::Radian mRotationY;
};
\end{lstlisting}


Dans la méthode InputListener::frameRenderingQueued, les touches pressées et les mouvements de la souris permettent soit le déplacement de la tête soit le déplacement de la caméra selon les lignes qui en fin de méthodes sont commentées.
\begin{lstlisting}[caption={InputListener.cpp}]
#include <OIS/OIS.h>
#include "InputListener.h"



InputListener::InputListener(RenderWindow* win, Camera* cam, SceneManager *sceneMgr,
                                bool bufferedKeys, bool bufferedMouse, bool bufferedJoy) 
    : ExampleFrameListener(win, cam, bufferedKeys, bufferedMouse, bufferedJoy)

    {
        mCamera = cam;
        mSceneMgr = sceneMgr;
        mVitesse = 100;
        mVitesseRotation = 0.3;
        mToucheAppuyee = false;
    }



bool InputListener::frameRenderingQueued(const FrameEvent& evt)
{
    //ces lignes permettent la mise a jour de nos objets pour obtenir le nom des touches enfoncees
   if(mMouse){
       mMouse->capture();
   }
   if(mKeyboard){
       mKeyboard->capture();
   }
   
   
   if(mKeyboard->isKeyDown(OIS::KC_ESCAPE)){
       mContinuer = false;
   }
   else{
       mContinuer= true;
   }
   
   Ogre::Vector3 deplacement = Ogre::Vector3::ZERO;
   mMouvement = mVitesse * evt.timeSinceLastFrame;
   
   
    // La touche A d un clavier QWERTY correspond au Q sur un AZERTY
    if ( mKeyboard->isKeyDown(OIS::KC_LEFT) || mKeyboard->isKeyDown(OIS::KC_A) ){
        deplacement.x -= mMouvement;
    }
    
    if ( mKeyboard->isKeyDown(OIS::KC_RIGHT) || mKeyboard->isKeyDown(OIS::KC_D) ){
        deplacement.x += mMouvement;
    }
    

    // W correspond au Z du AZERTY
    if ( mKeyboard->isKeyDown(OIS::KC_UP) || mKeyboard->isKeyDown(OIS::KC_W)){
        deplacement.z -= mMouvement;
    }
    
    if ( mKeyboard->isKeyDown(OIS::KC_DOWN) || mKeyboard->isKeyDown(OIS::KC_S)){
        deplacement.z += mMouvement;
    }
    
    //*
    const OIS::MouseState &mouseState = mMouse->getMouseState();
    mRotationX = Degree(-mouseState.Y.rel * mVitesseRotation);
    mRotationY = Degree(-mouseState.X.rel * mVitesseRotation);
    
    //pour que la camera bouge selon les touches pressees et le mouvement de la souris
    //mCamera->yaw(mRotationY);
    //mCamera->pitch(mRotationX);        
    //mCamera->moveRelative(deplacement);
    
    //pour que le noeud "nodeTete" bouge selon les touches pressees et le mouvement de la souris
    mSceneMgr->getSceneNode("nodeTete")->yaw(mRotationY);
    mSceneMgr->getSceneNode("nodeTete")->pitch(mRotationX);
    mSceneMgr->getSceneNode("nodeTete")->translate(deplacement, Ogre::Node::TS_LOCAL);
    
    return mContinuer;
}
\end{lstlisting}


\begin{lstlisting}[caption={PremiereApplication.h}]
using namespace std;

#include <ExampleApplication.h>
#include <OgreMovableObject.h>

#include "InputListener.h"


class PremiereApplication : public ExampleApplication
{
    public:
        void createScene();
        void createCamera();
        void createViewports();

        void createFrameListener();
        
        void createLux(std::string, MovableObject *);
};
\end{lstlisting}


\begin{lstlisting}[caption={PremiereApplication.cpp}]
#include "PremiereApplication.h"



void PremiereApplication::createFrameListener()
{
    mFrameListener = new InputListener(mWindow, mCamera, mSceneMgr, false, false, false);
    
    //root est l'element de base de l'application Ogre qui s'occupe notamment de gerer les frames listeners
    mRoot -> addFrameListener(mFrameListener);
}


void PremiereApplication::createScene()
{
    //creation d une entite
    Entity *head= mSceneMgr->createEntity("Tete", "ogrehead.mesh" );
    
    //creation d un noeud
    SceneNode *node= mSceneMgr->getRootSceneNode()->createChildSceneNode("nodeTete" , Vector3::ZERO, Quaternion::IDENTITY);
    
    node->yaw(Radian(Math::PI));
    node->yaw(Radian(Math::PI));

    //setPosition place le noeud aux coord passees en parametres
    Vector3 position = Vector3(30.0, 50.0, 0.0);
    node->setPosition(position);

    node->setPosition(30.0, 50.0, 0.0); 
    /*equivalent a
    Vector3 position = Vector3(30.0, 50.0, 0.0);
    node->setPosition(position);
    */

    //deplace le noeud par rapport a sa position actuelle
    node->translate(-30.0, 50.0, 0.0); //par defaut la trnslt se fait par rap a TS_WORLD
   
    //attachement de l entite au noeud
    node->attachObject(head);

    //creation d un plan
    Plane plan(Vector3::UNIT_Y, 0);

    //creation d un mesh cad l objet 3d visible ds la scene
    MeshManager::getSingleton().createPlane("sol",
                ResourceGroupManager::DEFAULT_RESOURCE_GROUP_NAME,
                plan, 500, 500, 10, 10, true, 1, 1, 1, Vector3::UNIT_Z); 

    //entite qui representera le plan
    Entity *ent= mSceneMgr->createEntity("EntiteSol", "sol");

    //ajout du materiau a l entite
    ent->setMaterialName("Examples/GrassFloor");//texture de pelouse
    /*les differents materiaux sont sous /media/materials/scritps, par ex:
    ent->setMaterialName("Examples/WaterStream");//texture d eau animee*/

    //creation d un noeud
    node = mSceneMgr->getRootSceneNode()->createChildSceneNode();
    node->attachObject(ent);

    createLux("ponctuelle", head);//lumiere ponctuelle
    //createLux("directionnelle", head);//lumiere directionnelle
    //createLux("spot", head);//lumiere projecteur

}

/*
cree une lumiere selon le parametre passe:
    createLux("ponctuelle"); -> lumiere ponctuelle
    createLux("directionnelle"); -> lumiere directionnelle
    createLux("spot"); -> lumiere projecteur

une lumiere noire est cree au debut de la methode

une ombre est cree en fin de methode
*/
void PremiereApplication::createLux(std::string prmLightType, MovableObject * prmEnt)
{
    //application d une couleur noire
    mSceneMgr->setAmbientLight(ColourValue(0.0, 0.0, 0.0)); 

    //definition d une lumiere 
    Light *light= mSceneMgr->createLight("lumiere1");

    if (prmLightType == "ponctuelle")
    {
        //definition du type de lumiere
        light->setType(Light::LT_POINT);//lumiere ponctuelle

        //definition de la position de la lumiere
        light->setPosition(-100, 200, 100);
    }
    else if (prmLightType == "directionnelle")
    {
        light->setType(Light::LT_DIRECTIONAL);//lumiere directionnelle
        light->setDirection(10.0, -20.0, -5);//vecteur directeur de la lumiere directionnelle

        //definition de la position de la lumiere
        light->setPosition(-100, 200, 100);
    }
    else
    {
        light->setType(Light::LT_SPOTLIGHT);//lumiere directionnelle
        light->setDirection(0.0, -1, 1);//vecteur directeur de la lumiere directionnelle
        light->setSpotlightRange(Degree(30), Degree(60), 1.0);
    }

    //definition des couleur des lumieres diffuse
    light->setDiffuseColour(1.0, 0.7, 0.1);
    //et speculaire
    light->setSpecularColour(1.0, 0.7, 0.1);

    //ombre
    //activation de la projection des ombres
    light->setCastShadows(true);
    prmEnt->setCastShadows(true);

    //activation des ombres
    mSceneMgr->setShadowTechnique(Ogre::SHADOWTYPE_STENCIL_ADDITIVE);
}

/*definit la position de notre point de vue*/
void PremiereApplication::createCamera()
{
    //creation de la camera
    mCamera = mSceneMgr->createCamera("Ma Camera");

    //position de la camera
    mCamera->setPosition(Vector3(-100.0, 150.0, 200.0));

    //permet de determiner le point de la scene que regarde notre camera
    mCamera->lookAt(Vector3(0.0, 100.0, 0.0));

    //definition des distances de near clip et de far clip, qui
    //sont les distances minimale et maximale auxquelles doit se
    //trouver un objet pour etre afficher a l'ecran.
    mCamera->setNearClipDistance(1);
    mCamera->setFarClipDistance(1000);
}

void PremiereApplication::createViewports()
{
    //la creation du Viewport, appelee par la fenetre et prenant en parametre la
    //camera concernee, le premier parametre est la camera de laqll le contenu
    //du viewport sera rendu, ce paramatre est le seul obligatoire
    Viewport *vue = mWindow->addViewport(mCamera);
    //Viewport *vue = mWindow->addViewport(mCamera, 0, 0, 0, 0.8, 0.8);

    //Grace a ce Viewport nouvellement cree, nous allons faire coincider
    //le rapport largeur / hauteur de notre camera avec celui du
    //Viewport, pour avoir une image non deformee
    mCamera->setAspectRatio(Real(vue->getActualWidth()) /  Real(vue->getActualHeight()));

    //on definit ici la couleur de fond
    vue->setBackgroundColour(ColourValue(0.0, 0.0, 1.0));     //bleu
    //vue->setBackgroundColour(ColourValue(0.980, 0.502, 0.447)); //saumon

   // creation d'un viewport dans le coin bas gauche
   //les parametres autres que le premier sont obligatoires pour la definition
   //de plusieurs viewport
   Viewport* vue2 = mWindow->addViewport(mCamera, 1, 0, 0.8, 0.2, 0.2);
   vue2->setBackgroundColour(ColourValue(0.561, 0.737, 0.561 ));  //darkseagreen
}


\end{lstlisting}






Puisque nous avons ajouté un fichier source il est nécessaire de modifier le fichier CMakeLists.txt tel que suit:

\begin{lstlisting}[caption={CMakeLists.txt}]
project(helloworld)
cmake_minimum_required(VERSION 2.6)

set(CMAKE_MODULE_PATH "/usr/share/OGRE/cmake/modules")


# Il faut indiquer a cmake ou se trouvent les includes en question
#include_directories ("/home/adkoba/Workspace/ogre_src_v1-8-1/Samples/Common/include")
include_directories ("include")

# Bien sur, pour compiler Ogre, il faut le chercher, et definir le repertoire contenant les includes.
find_package(OGRE REQUIRED)
include_directories (${OGRE_INCLUDE_DIRS})

# L'exemple depend aussi de OIS, une lib pour gerer la souris, clavier, joystick...
find_package(OIS REQUIRED)

# On definit les sources qu'on veut compiler
SET( SOURCES
  src/InputListener.cpp  
  src/PremiereApplication.cpp
  src/main.cpp
)

# On les compile
add_executable (
  premiereapp ${SOURCES}
)

# Et pour finir, on lie l'excutable avec les librairies que find_package nous a gentillement trouve.
target_link_libraries(premiereapp ${OGRE_LIBRARY} ${OIS_LIBRARY} -lboost_system)

set( RESOURCES_FILE
  media/
  plugins/
  resources/ogre.cfg
  resources/plugins.cfg
  resources/resources.cfg
)

# do the copying
foreach( file_i ${RESOURCES_FILE})
    add_custom_command(
      TARGET premiereapp
      POST_BUILD
      COMMAND cp -R ${CMAKE_SOURCE_DIR}/${file_i} ${CMAKE_BINARY_DIR}
      COMMENT "copy file ${file_i}"
      )
endforeach( file_i )
\end{lstlisting}

Comme nous pouvons le voir nous avons juste modifié la liste des sources du projet












\section{Avec buffer, c'est plus simple ?}

La méthode présentée ci-avant pour contrôler si une touche vient ou non d'être appuyée fonctionne mais est peu pratique si on doit surveiller quinze touches.

Heureusement, OIS a pensé à tout, nous allons donc voir une autre façon de faire ce que l'on vient juste d'écrire. On va commencer comme précédemment par le déplacement de la caméra, puis on verra comment gérer notre interrupteur.


\subsection{Mise en place}


Nous allons commencer par activer l'utilisation du buffer pour la souris et le clavier lors de la construction de notre frame listener. Il suffit pour cela de mettre les paramètres correspondants à true.


\begin{lstlisting}[caption={Activation du buffer pour la souris et le clavier}]
void PremiereApplication::createFrameListener()
{
    mFrameListener= new InputListener(mWindow, mCamera, mSceneMgr, true, true, false);    mRoot->addFrameListener(mFrameListener);
}
\end{lstlisting}


C'est quasiment tout , il va simplement falloir rajouter deux petites lignes dans le constructeur pour que tout soit prêt.

Afin d'utiliser le buffer, il faut fournir un objet (un ''écouteur'' dérivant d'une des classes OIS::***Listener selon le périphérique à écouter) qui sera celui qui recevra les événements du type ''cette touche vient d'être appuyée, que dois-je faire ?''. Pour cela, OIS fournit une méthode pour chacun de trois périphériques d'entrée (clavier, souris, joystick) :


\begin{itemize}
\item virtual void OIS::Mouse::setEventCallback(OIS::MouseListener* mouseListener);
\item  virtual void OIS::Keyboard::setEventCallback(OIS::KeyListener* keyListener);
\item  virtual void OIS::JoyStick::setEventCallback(OIS::JoyStickListener* joystickListener);
\end{itemize}

Cette méthode prend donc en paramètre un pointeur sur un listener du périphérique que vous voulez utiliser. Nous allons donc rajouter deux classes mères à notre InputListener : OIS::MouseListener et OIS::KeyListener. Modifiez donc la déclaration de la classe InputListener :

\begin{lstlisting}[caption={Classes mères pour gestion des Listeners}]
class InputListener : public ExampleFrameListener, OIS::KeyListener, OIS::MouseListener
\end{lstlisting}

Dans le constructeur, vous pouvez maintenant insérer les deux lignes suivantes (mMouse et mKeyboard sont déclarées dans ExampleFrameListener) :

\begin{lstlisting}[caption={Enregistrement des listener}]
mMouse->setEventCallback(this);
mKeyboard->setEventCallback(this);
\end{lstlisting}

Vous ne pouvez enregistrer qu'un seul écouteur par périphérique d'entrée. En cas d'appels multiples à la méthode setEventCallback(), c'est le dernier appel qui définit l'écouteur à utiliser. Pour que différents objets reçoivent les événements, il faudra donc les redistribuer à partir de l'écouteur receveur.

Au chapitre des modifications, supprimez les anciens attributs d'InputListener et mettez ceux-ci :

\begin{lstlisting}[caption={Attributs d'InputListener}]
private:
    Ogre::SceneManager *mSceneMgr;
    bool mContinuer;
    Ogre::Vector3 mMouvement;
    Ogre::Real mVitesse;
    Ogre::Real mVitesseRotation;
\end{lstlisting}

En initialisant ces attributs, votre constructeur devrait maintenant ressembler à ceci :

\begin{lstlisting}[caption={Constructeur d'InputListener}]
InputListener(RenderWindow* win, Camera* cam, SceneManager *sceneMgr, bool bufferedKeys = false, bool bufferedMouse = false, bool bufferedJoy = false )   : ExampleFrameListener(win, cam, bufferedKeys, bufferedMouse, bufferedJoy)
{
    mSceneMgr = sceneMgr;
    mContinuer = true;  //permettra d'enregistrer l'appui sur la touche Echap
    mMouvement = Ogre::Vector3::ZERO;//vecteur de la direction ds laquelle se deplacer
    mVitesse = 100;
    mVitesseRotation = 0.2;//facteur multiplicatif pr ajuster la vitesse de la cam 
    mMouse->setEventCallback(this);
    mKeyboard->setEventCallback(this);
}
\end{lstlisting}

L'attribut mContinuer permettra d'enregistrer l'appui sur la touche Echap, mMouvement sera le vecteur de la direction dans laquelle on doit se déplacer et mVitesseRotation un facteur multiplicatif permettant d'ajuster la vitesse de rotation de la caméra.

On met à jour la valeur de retour de la méthode frameRenderingQueued().

\begin{lstlisting}[caption={}]
bool InputListener::frameRenderingQueued(const Ogre::FrameEvent& evt)
{
    if(mMouse)
        mMouse->capture();
    if(mKeyboard)
        mKeyboard->capture();

    return mContinuer;
}
\end{lstlisting}

Enfin, il y a des méthodes virtuelles pures à réimplémenter dans notre classe. Ces méthodes seront appelées lors de l'événement correspondant sur le clavier (touche enfoncée ou rel\^achée) ou sur la souris (bouton appuyé ou rel\^aché, déplacement). De même que les méthodes des frame listeners d'Ogre, elles renvoient un booléen que l'on utilisera pour savoir si l'on doit interrompre le programme.

Ajoutons donc les prototypes dans notre header et un simple retour de valeur dans le corps des méthodes pour commencer.

Contrairement aux méthodes des frame listeners, la valeur de retour ne détermine pas si l'on doit continuer ou non l'exécution. C'est pour cela que l'on devra passer par l'attribut mContinuer pour surveiller l'appui sur la touche Echap.


\begin{lstlisting}[caption={Méthodes virtuelles appelées lors d'un évènement sur un périphérique}]
bool InputListener::mouseMoved(const OIS::MouseEvent &e)
{
    return true;
}

bool InputListener::mousePressed(const OIS::MouseEvent &e, OIS::MouseButtonID id)
{
    return true;
}

bool InputListener::mouseReleased(const OIS::MouseEvent &e, OIS::MouseButtonID id)
{
    return true;
}

bool InputListener::keyPressed(const OIS::KeyEvent &e)
{
    return true;
}

bool InputListener::keyReleased(const OIS::KeyEvent &e)
{
    return true;
}
\end{lstlisting}

On commence par implémenter la touche Echap. Si elle est appuyée, on passe simplement l'attribut mContinuer à false.

\begin{lstlisting}[caption={Implémentation de l'appuie sur ECHAP}]
bool InputListener::keyPressed(const OIS::KeyEvent &e)
{
    switch(e.key)
    {
        case OIS::KC_ESCAPE:
            mContinuer = false;
            break;
    }

    return mContinuer;
}
\end{lstlisting}

On gère ensuite l'appui sur les touches de déplacement en modifiant les composantes de mMouvement en fonction de la touche. On va aussi multiplier la vitesse de déplacement par deux lorsque l'on appuie sur la touche majuscule gauche.

\begin{lstlisting}[caption={Implémentation de l'appuie sur les touches de déplacement}]
bool InputListener::keyPressed(const OIS::KeyEvent &e)
{
    switch(e.key)
    {
        case OIS::KC_ESCAPE:
            mContinuer = false;
            break;
        case OIS::KC_W:
            mMouvement.z -= 1;
            break;
        case OIS::KC_S:
            mMouvement.z += 1;
            break;
        case OIS::KC_A:
            mMouvement.x -= 1;
            break;
        case OIS::KC_D:
            mMouvement.x += 1;
            break;
        case OIS::KC_LSHIFT:
            mVitesse *= 2;
            break;
    }

    return mContinuer;
}
\end{lstlisting}

Enfin, dans la méthode keyReleased, on va ''retirer'' la composante que l'on ajoute lors de l'appui sur une touche. Le code est donc semblable, seuls les signes changent.

\begin{lstlisting}[caption={}]
bool InputListener::keyReleased(const OIS::KeyEvent &e)
{
    switch(e.key)
    {
        case OIS::KC_W:
            mMouvement.z += 1;
            break;
        case OIS::KC_S:
            mMouvement.z -= 1;
            break;
        case OIS::KC_A:
            mMouvement.x += 1;
            break;
        case OIS::KC_D:
            mMouvement.x -= 1;
            break;
        case OIS::KC_LSHIFT:
            mVitesse /= 2;
            break;
    }

    return true;
}
\end{lstlisting}

Maintenant que l'on gère correctement l'évolution de nos variables de mouvement et de vitesse de déplacement, il faut écrire le déplacement de la caméra dans la méthode frameRenderingQueued().

\begin{lstlisting}[caption={Implémentation du déplacement de la caméra dans la méthode frameRenderingQueued}]
virtual bool frameRenderingQueued(const FrameEvent& evt)
{
    if(mMouse)
        mMouse->capture();

    if(mKeyboard)
        mKeyboard->capture();

    Ogre::Vector3 deplacement = Ogre::Vector3::ZERO;
    deplacement = mMouvement * mVitesse * evt.timeSinceLastFrame;
    mCamera->moveRelative(deplacement);

    return mContinuer;
}
\end{lstlisting}

Pour la rotation de la caméra, tout se passe dans la méthode mouseMoved(), dont l'événement reçu en paramètre contient l'état de la souris, permettant comme précédemment de retrouver le déplacement relatif de la souris.

On multiplie cette valeur relative par la vitesse de rotation, on fait attention aux signes, et voici ce qu'on obtient :

\begin{lstlisting}[caption={Implémentation de la rotation de la caméra dans la méthode mouseMoved}]
bool InputListener::mouseMoved(const OIS::MouseEvent &e)
{
    mCamera->yaw(Ogre::Degree(-mVitesseRotation * e.state.X.rel));
    mCamera->pitch(Ogre::Degree(-mVitesseRotation * e.state.Y.rel));

    return true;
}
\end{lstlisting}

Vous pouvez maintenant compiler et exécuter votre application ; les commandes de déplacement sont maintenant gérées entièrement par notre classe InputListener, n'hésitez donc pas à adapter les variables initialisées dans le constructeur si vous voulez accélérer ou ralentir les mouvements par exemple.\newline

Cette méthode de gestion des entrées permet donc de gérer plus facilement l'appui ponctuel sur une touche, tout en conservant une gestion simple des touches qui peuvent rester enfoncées (pour le déplacement ici).

Gardez cependant bien à l'esprit qu'\textbf{il ne peut y avoir qu'un seul écouteur par périphérique d'entrée} et qu'il faudra donc penser à rapporter l'appui sur les touches à des écouteurs annexes lorsque votre application grossira, sinon vous allez vite vous retrouver avec un code lourd et mal organisé.\newline

Dans ce chapitre, nous avons vu comment gérer nous-mêmes les entrées de l'utilisateur avec la bibliothèque OIS, ainsi que le principe des frame listeners, qui nous ont ici été bien utiles alors que nous n'avons pas encore vu le fonctionnement de la boucle de rendu.

Le prochain chapitre promet d'être intéressant : nous allons en effet utiliser le module de terrain d'Ogre qui a été refait dans la version 1.7 et qui offre une gestion beaucoup plus optimisée des terrains par rapport aux versions précédentes. Je n'en dis pas plus, on se retrouve de l'autre côté.


\subsection{Code}

Le CMakeLists.txt n'est pas modifié par rapport à la gestion des entrées sans buffer.


\begin{lstlisting}[caption={PremiereApplication::createFrameListener()}]
void PremiereApplication::createFrameListener()
{
    //activation du buffer pour la souris et le clavier
    mFrameListener = new InputListener(mWindow, mCamera, mSceneMgr, true, true, true);
    
    //root est l'element de base de l'application Ogre qui s'occupe notamment de gerer les frames listeners
    mRoot -> addFrameListener(mFrameListener);
}

\end{lstlisting}














\begin{lstlisting}[caption={InputListener.h}]
#include "ExampleFrameListener.h"

//nous utiliserons OIS pour gerer les entrees de l'utilisateur
#include <OIS/OIS.h>

//la classe ExampleFrameListener ExampleApplication met deja en oeuvre une gestion des entrees et attend un ExampleFrameListener
//ExampleFrameListener s'occupe aussi de construire les objets necessaires a l'ecoute des entrees
class InputListener : public ExampleFrameListener, OIS::KeyListener, OIS::MouseListener
{
    public:
        InputListener(RenderWindow* win, Camera* cam, SceneManager *sceneMgr, 
                        bool bufferedKeys = false, bool bufferedMouse = false, 
                        bool bufferedJoy = false);
        
        //nous allons juste devoir redefinir frameRenderingQueued() pour implementer notre propre gestion des entrees a la place de celle prevue par ExampleFrameListener.
        virtual bool frameRenderingQueued(const FrameEvent& evt);
        
        //les 5 methodes suivantes sont des methodes virtuelles pures a reimplementer
        //ces methodes seront appelees lors de levenmnt correspondant, leur valeur de retour ne dit pas si on doit continuer ou pas, d'ou l'interet de mContinuer
        bool mouseMoved(const OIS::MouseEvent &e);      //evenmnt: la souris a bouge
        bool mousePressed(const OIS::MouseEvent &e, OIS::MouseButtonID id);//evenmnt: un bouton de la souris a ete presse
        bool mouseReleased(const OIS::MouseEvent &e, OIS::MouseButtonID id);//evenmnt: un bouton de la souris a ete relache 
        bool keyPressed(const OIS::KeyEvent &e);//evenmnt: un bouton a ete presse 
        bool keyReleased(const OIS::KeyEvent &e);//evenmnt: un bouton a ete relache 
        

        private:
            Ogre::SceneManager *mSceneMgr;
            Ogre::Camera *mCamera;
            
            //permettra d'enregistrer l'appuie sur ECHAP
            bool mContinuer;

            //vecteur de la direction ds lqll on doit bouger
            Ogre::Vector3 mMouvement;
            Ogre::Real mVitesse;
            
            //pour ajuster la vitesse de rotation de la souris
            Ogre::Real mVitesseRotation;

            Ogre::Radian mRotationX;
            Ogre::Radian mRotationY;
};

\end{lstlisting}













\begin{lstlisting}[caption={InputListener.cpp}]



#include <OIS/OIS.h>
#include "InputListener.h"



InputListener::InputListener(RenderWindow* win, Camera* cam, SceneManager *sceneMgr,
                                bool bufferedKeys, bool bufferedMouse, bool bufferedJoy) 
    : ExampleFrameListener(win, cam, bufferedKeys, bufferedMouse, bufferedJoy)
    {
        mCamera = cam;
        mSceneMgr = sceneMgr;
        
        mContinuer = true;//permettra l enregistrmnt de l appuie sur ECHAP
        mMouvement = Ogre::Vector3::ZERO;//sera le vct de la direction ds laqll on doit se deplacer
        
        mVitesse = 100;
        mVitesseRotation = 0.3;//fcteur multiplicatif pour ajuster la rotation de la camera
       
        //enregistrement d un ecouteur pour la souris et pour le clavier
        mMouse->setEventCallback(this);
        mKeyboard->setEventCallback(this);
    }



bool InputListener::frameRenderingQueued(const FrameEvent& evt)
{
    //ces lignes permettent la mise a jour de nos objets pour obtenir le nom des touches enfoncees
   if(mMouse){
       mMouse->capture();
   }
   if(mKeyboard){
       mKeyboard->capture();
   }
   
   //gestion du mouvement de la camera
   Ogre::Vector3 deplacement = Ogre::Vector3::ZERO;
   deplacement = mMouvement * mVitesse * evt.timeSinceLastFrame;
   mCamera->moveRelative(deplacement);
    
   return mContinuer;
}



//les 5 methodes suivantes sont des methodes virtuelles pures a reimplementer
//si la souris a bouge
bool InputListener::mouseMoved(const OIS::MouseEvent &e)
{    
    mCamera->yaw(Ogre::Degree(-mVitesseRotation * e.state.X.rel));
    mCamera->pitch(Ogre::Degree(-mVitesseRotation * e.state.Y.rel));
    
    return true;
}

//si une touche de la souris est pressee
bool InputListener::mousePressed(const OIS::MouseEvent &e, OIS::MouseButtonID id)
{
    return true;
}

//si une touche de la souris est relachee 
bool InputListener::mouseReleased(const OIS::MouseEvent &e, OIS::MouseButtonID id)
{
    return true;
}

//si une touche est pressee
bool InputListener::keyPressed(const OIS::KeyEvent &e)
{
    switch(e.key)
    {
        case OIS::KC_ESCAPE:
            mContinuer = false;
            break;
        case OIS::KC_W:
            mMouvement.z -= 1;
            break;
        case OIS::KC_S:
            mMouvement.z += 1;
            break;
        case OIS::KC_A:
            mMouvement.x -= 1;
            break;
        case OIS::KC_D:
            mMouvement.x += 1;
            break;
        case OIS::KC_LSHIFT:
            mVitesse *= 2;
            break;
    }
    
    return true;
}

//si une touche est relachee
bool InputListener::keyReleased(const OIS::KeyEvent &e)
{
    
    switch(e.key)
    {
        case OIS::KC_W:
            mMouvement.z += 1;
            break;
        case OIS::KC_S:
            mMouvement.z -= 1;
            break;
        case OIS::KC_A:
            mMouvement.x += 1;
            break;
        case OIS::KC_D:
            mMouvement.x -= 1;
            break;
        case OIS::KC_LSHIFT:
            mVitesse /= 2;
            break;
    } 
    
    return true;
}
\end{lstlisting}